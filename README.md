# Big-Data-Pipeline-with-Pyspark
In this project I built Batch End to end Big data pipeline using Hadoop, Hive, and Pyspark with USA Prescriber Dataset.

## Tech that use in this project
1. Python 3
2. Java Development Kit (JDK) 8
3. Google Cloud Platform (Virtual Machine)
4. Hadoop HDFS and YARN ver. 3.3.4
5. PostgreSQL in Docker Container
6. Hive ver 3.1.2
7. Apache Spark ver 3.2.1
8. Amazon S3 Bucket
